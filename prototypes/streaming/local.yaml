cluster_name: jupiter

## NOTE: Typically for local clusters, min_workers == initial_workers == max_workers.

# The minimum number of workers nodes to launch in addition to the head
# node. This number should be >= 0.
# Typically, min_workers == initial_workers == max_workers.
min_workers: 1
# The initial number of worker nodes to launch in addition to the head node.
# Typically, min_workers == initial_workers == max_workers.
initial_workers: 1

# The maximum number of workers nodes to launch in addition to the head node.
# This takes precedence over min_workers.
# Typically, min_workers == initial_workers == max_workers.
max_workers: 1

# Autoscaling parameters.
# Ignore this if min_workers == initial_workers == max_workers.
autoscaling_mode: default
target_utilization_fraction: 1.
idle_timeout_minutes: 5

# This executes all commands on all nodes in the docker container,
# and opens all the necessary ports to support the Ray cluster.
# Empty string means disabled. Assumes Docker is installed.
#docker:
#    image: "rayproject/ray-ml:latest" # e.g., tensorflow/tensorflow:1.5.0-py3
#    container_name: "ray_docker" # e.g. ray_docker
#    # If true, pulls latest version of image. Otherwise, `docker run` will only pull the image
#    # if no cached version is present.
#    pull_before_run: True
#    run_options: []# Extra options to pass into "docker run"

# Local specific configuration.
provider:
    type: local
    #coordinator_address: 192.168.1.172:6379
    head_ip: 127.0.0.1
    #:6379
    worker_ips: []

# How Ray will authenticate with newly launched nodes.
auth:
    ssh_user: mat
    ssh_private_key: /home/mat/.ssh/id_rsa

# Leave this empty.
head_node: {}

# Leave this empty.
worker_nodes: {}

# Files or directories to copy to the head and worker nodes. The format is a
# dictionary from REMOTE_PATH: LOCAL_PATH, e.g.
file_mounts: {}
#    "/path1/on/remote/machine": "/path1/on/local/machine",
#    "/path2/on/remote/machine": "/path2/on/local/machine",
#}

# List of commands that will be run before `setup_commands`. If docker is
# enabled, these commands will run outside the container and before docker
# is setup.
initialization_commands: []
    # - pyenv activate stem_field

# List of shell commands to run to set up each nodes.
setup_commands: []
    # - pyenv activate stem_field
# https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-1.1.0.dev0-cp37-cp37m-manylinux1_x86_64.whl

# Custom commands that will be run on the head node after common setup.
head_setup_commands: []

# Custom commands that will be run on worker nodes after common setup.
worker_setup_commands: []

# # Command to start ray on the head node. You don't need to change this.
# head_start_ray_commands:
    # - pyenv activate stem_field
    # - pyenv activate stem_field && ray stop
    # - ulimit -n 65536; pyenv activate stem_field && ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml

# Command to start ray on worker nodes. You don't need to change this.
# worker_start_ray_commands:
    # - pyenv activate stem_field
    # - ray stop
    # - ulimit -n 65536; ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076
    # - ray start --head
